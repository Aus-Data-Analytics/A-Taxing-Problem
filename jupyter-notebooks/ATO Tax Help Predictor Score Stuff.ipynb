{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn import preprocessing\n",
    "#import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# process 2018 tax help data\n",
    "ato2016_data = pd.read_excel(\"atoabsgovhack2018.xlsx\", sheetname=\"ATO Data\")\n",
    "abs2016_data = pd.read_excel(\"atoabsgovhack2018.xlsx\", sheetname=\"ABS Data\")\n",
    "txc_data = pd.read_excel(\"atoabsgovhack2018.xlsx\", sheetname=\"Tax Help Center\")\n",
    "seifa_data = pd.read_excel(\"atoabsgovhack2018.xlsx\", sheetname=\"ABS SEIFA \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean 2018 tax help data\n",
    "txc_data.rename(columns={'Post Code': 'Postcode'}, inplace=True)\n",
    "seifa_data.rename(columns={'Postal Area (POA) Code': 'Postcode'}, inplace=True)\n",
    "seifa_data.rename(columns={'Year': 'Income year'}, inplace=True)\n",
    "seifa_data[\"Income year\"] = seifa_data[\"Income year\"].apply(lambda x: 2015 if x == 2011 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process 2017 tax help data\n",
    "ato2015_data = pd.read_excel(\"atoabsgovhack2017.xlsx\", sheetname=\"Data\", skiprows=0, usecols=[0,1,2,*range(3, 17)])\n",
    "abs2015_data = pd.read_excel(\"atoabsgovhack2017.xlsx\", sheetname=\"Data\", skiprows=0, usecols=[0,1,2,*range(17, 56)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# clean 2017 tax help data\n",
    "ato2015_data = ato2015_data.loc[ato2015_data['Income year'] == 2015]\n",
    "abs2015_data = abs2015_data.loc[abs2015_data['Income year'] == 2015]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process 2016 ato stats\n",
    "df = pd.read_excel(\"taxstats2016individual06taxablestatusstateterritorypostcodetaxableincome.xlsx\", sheetname=\"Individuals Table 6B\", skiprows=2, usecols=[1, 2, 4, 37, 39, 85, 93, 107, 129])\n",
    "ato2016_stats = pd.DataFrame()\n",
    "ato2016_stats['average income per person'] = df[df.columns[2]]/df[df.columns[1]]\n",
    "ato2016_stats['unfranked ratio'] = df[df.columns[3]]/df[df.columns[1]]\n",
    "ato2016_stats['franked ratio'] = df[df.columns[4]]/df[df.columns[1]]\n",
    "ato2016_stats['cgt ratio'] = df[df.columns[5]]/df[df.columns[1]]\n",
    "ato2016_stats['foreign income ratio'] = df[df.columns[6]]/df[df.columns[1]]\n",
    "ato2016_stats['rent ratio'] = df[df.columns[7]]/df[df.columns[1]]\n",
    "ato2016_stats['business ratio'] = df[df.columns[8]]/df[df.columns[1]]\n",
    "\n",
    "x = ato2016_stats.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "ato2016_stats_norm = pd.DataFrame(x_scaled, columns=ato2016_stats.columns)\n",
    "\n",
    "ato2016_stats_norm['average'] = ato2016_stats_norm.mean(axis=1)\n",
    "ato2016_stats_norm[\"average\"] = ato2016_stats_norm[\"average\"].apply(lambda x: 1 - x)\n",
    "ato2016_stats_norm['Postcode'] = df['Postcode']\n",
    "ato2016_stats_norm = ato2016_stats_norm.loc[ato2016_stats_norm['Postcode'].isin(list(range(100,9999)))]\n",
    "ato2016_stats_norm['Postcode'] = ato2016_stats_norm['Postcode'].astype(np.int64)\n",
    "ato2016_stats_norm['Income year'] = 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# process 2015 ato stats\n",
    "df = pd.read_excel(\"taxstats2015individual06taxablestatusstateterritorypostcode.xlsx\", sheetname=\"Individuals Table 6B\", skiprows=2, usecols=[1, 2, 4, 37, 39, 79, 87, 101, 123])\n",
    "ato2015_stats = pd.DataFrame()\n",
    "ato2015_stats['average income per person'] = df[df.columns[2]]/df[df.columns[1]]\n",
    "ato2015_stats['unfranked ratio'] = df[df.columns[3]]/df[df.columns[1]]\n",
    "ato2015_stats['franked ratio'] = df[df.columns[4]]/df[df.columns[1]]\n",
    "ato2015_stats['cgt ratio'] = df[df.columns[5]]/df[df.columns[1]]\n",
    "ato2015_stats['foreign income ratio'] = df[df.columns[6]]/df[df.columns[1]]\n",
    "ato2015_stats['rent ratio'] = df[df.columns[7]]/df[df.columns[1]]\n",
    "ato2015_stats['business ratio'] = df[df.columns[8]]/df[df.columns[1]]\n",
    "\n",
    "x = ato2015_stats.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "ato2015_stats_norm = pd.DataFrame(x_scaled, columns=ato2015_stats.columns)\n",
    "\n",
    "ato2015_stats_norm['average'] = ato2015_stats_norm.mean(axis=1)\n",
    "ato2015_stats_norm[\"average\"] = ato2015_stats_norm[\"average\"].apply(lambda x: 1 - x)\n",
    "ato2015_stats_norm['Postcode'] = df['Postcode']\n",
    "ato2015_stats_norm = ato2015_stats_norm.loc[ato2015_stats_norm['Postcode'].isin(list(range(100,9999)))]\n",
    "ato2015_stats_norm['Postcode'] = ato2015_stats_norm['Postcode'].astype(np.int64)\n",
    "ato2015_stats_norm['Income year'] = 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join datasets\n",
    "df = pd.DataFrame()\n",
    "df = df.append(ato2016_data)\n",
    "df = df.append(ato2015_data)\n",
    "abs_data = abs2016_data.append(abs2015_data)\n",
    "df = df.merge(abs_data, on=[\"Income year\", \"Postcode\"], how=\"outer\")\n",
    "ato_stats = ato2016_stats_norm.append(ato2015_stats_norm)\n",
    "df = df.merge(ato_stats, on=[\"Income year\", \"Postcode\"], how=\"outer\")\n",
    "df = df.merge(seifa_data, on=[\"Income year\", \"Postcode\"], how=\"outer\")\n",
    "df = df.merge(txc_data, on=\"Postcode\", how=\"outer\")\n",
    "df.fillna(0, inplace=True)\n",
    "# TEMPORARY: limit to 2015/2016 data\n",
    "df = df[df['Income year'].isin([2016, 2015])]\n",
    "\n",
    "df['average_bucket'] = pd.cut(df['average'].values, bins=len(df['Count'].unique()), labels = list(range(0,len(df['Count'].unique()))))\n",
    "count_bucket_dict = {v: k for k, v in dict(enumerate(sorted(df['Count'].unique()))).items()}\n",
    "df['count_bucket'] = df[\"Count\"].apply(lambda x: count_bucket_dict[x])\n",
    "\n",
    "df[\"score\"] = df['average_bucket'] == df['count_bucket']\n",
    "df[\"score\"] = df[\"score\"].apply(lambda x: 1 if x else 0)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[\"score\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# specify features columns\n",
    "features = df.columns[3:-3]\n",
    "df[features].columns\n",
    "\n",
    "# feature correlations\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    count_corr = df[['Count'] + list(features)].corr(method='pearson')['Count']\n",
    "    display(count_corr[count_corr > 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create label column and train/test split\n",
    "df['label'] = df['Count']\n",
    "# df['label'] = (df['Count'] > 1).astype(np.int64)\n",
    "df['is_train'] = np.random.uniform(0, 1, len(df)) <= .80\n",
    "train, test = df[df['is_train']==True], df[df['is_train']==False]\n",
    "print(\"Train Class Balance:\", train[train['label']==0].shape[0], \" / \", train[train['label']==1].shape[0])\n",
    "print(\"Test Class Balance:\", test[test['label']==0].shape[0], \" / \", test[test['label']==1].shape[0])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# build predictive model\n",
    "rf = RandomForestClassifier(class_weight='balanced', n_estimators=1000, oob_score=True)\n",
    "rf.fit(train[features], train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# model accuracy (out of bag and test set)\n",
    "accuracy = accuracy_score(test['label'], rf.predict(test[features]))\n",
    "print(f'Out-of-bag score estimate: {rf.oob_score_:.3}')\n",
    "print(f'Mean accuracy score: {accuracy:.3}')\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(rf, train[features], train['label'], cv=5)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# confusion matrix for test set\n",
    "cm = pd.DataFrame(confusion_matrix(test['label'], rf.predict(test[features])), columns=test['label'].unique(), index=test['label'].unique())\n",
    "sns.heatmap(cm, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# top ten features\n",
    "feature_importances = [(feature, round(importance, 2)) for feature, importance in zip(train[features], list(rf.feature_importances_))]\n",
    "feature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)\n",
    "[print('Variable: {:50} Importance: {}'.format(*pair)) for pair in feature_importances[:10]];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
